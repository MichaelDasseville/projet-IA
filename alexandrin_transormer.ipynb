{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/transformer\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import io\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus of wikipedia length: 8259\n"
     ]
    }
   ],
   "source": [
    "#import text from \n",
    "import wikipediaapi\n",
    "import requests\n",
    "wiki = wikipediaapi.Wikipedia('fr',extract_format=wikipediaapi.ExtractFormat.WIKI)\n",
    "S = requests.Session()\n",
    "URL = 'https://fr.wikipedia.org/w/api.php'\n",
    "PARAMS = {\"action\":\"query\",\n",
    "         \"format\":\"json\",\n",
    "         \"list\":\"random\",\n",
    "         \"rnlimit\":\"500\"}\n",
    "R = S.get(url=URL, params = PARAMS)\n",
    "DATA = R.json()\n",
    "\n",
    "RANDOMS = DATA[\"query\"][\"random\"]\n",
    "\n",
    "txt = ''\n",
    "for r in RANDOMS:\n",
    "    page_rnd = wiki.page(r[\"title\"])\n",
    "    txt += page_rnd.text\n",
    "    \n",
    "crps = txt.lower().split('.')\n",
    "crps = list(filter(lambda a: len(a) > 2, crps))\n",
    "print('corpus of wikipedia length:', len(crps))\n",
    "input_sequences = []\n",
    "for line in crps:\n",
    "    input_sequences.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus of poetry length: 388904\n"
     ]
    }
   ],
   "source": [
    "#import text from dramacode\n",
    "with io.open('alexandrin.txt', encoding='utf-8') as f:\n",
    "    data = f.read().lower()\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "#corpus = list(filter(lambda a: len(a) < 100, corpus))\n",
    "corpus = list(filter(lambda a: len(a) > 2, corpus))\n",
    "print('corpus of poetry length:', len(corpus))\n",
    "#tokenizer.fit_on_texts(corpus)\n",
    "#total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "for line in corpus:\n",
    "    input_sequences.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total corpus length: 198581.5\n"
     ]
    }
   ],
   "source": [
    "# We want to predit the next sentence from a sentence \n",
    "n_seq = len(input_sequences)    \n",
    "output_sequences = input_sequences[1:n_seq:2]\n",
    "input_sequences = input_sequences[:n_seq-1:2]\n",
    "print(\"total corpus length:\", n_seq/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(corpus, target_vocab_size=2**15)\n",
    "tokenizer.save_to_file('vocab_enconder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.SubwordTextEncoder.load_from_file('vocab_enconder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((input_sequences,output_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer.vocab_size] + tokenizer.encode(\n",
    "        lang1.numpy()) + [tokenizer.vocab_size+1]\n",
    "    lang2 = [tokenizer.vocab_size] + tokenizer.encode(\n",
    "        lang2.numpy()) + [tokenizer.vocab_size+1]\n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length, tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(input_, output_):\n",
    "    return tf.py_function(encode, [input_, output_], [tf.int64, tf.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nval_dataset = val_examples.map(tf_encode)\\nval_dataset = val_dataset.filter(filter_max_length).padded_batch(\\n    BATCH_SIZE, padded_shapes=([-1], [-1]))\\n    '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "'''\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer.vocab_size + 2\n",
    "target_vocab_size = tokenizer.vocab_size + 2\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt_batch = next(iter(data_alex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "    print ('Attention weights are:')\n",
    "    print (temp_attn)\n",
    "    print ('Output is:')\n",
    "    print (temp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "          x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, \n",
    "            look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "          x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "          attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "          attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "             look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    #ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                     True, \n",
    "                                     enc_padding_mask, \n",
    "                                     combined_mask, \n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [tokenizer.vocab_size]\n",
    "    end_token = [tokenizer.vocab_size + 1]\n",
    "\n",
    "    # inp sentence is portuguese, hence adding the start and end token\n",
    "    inp_sentence = start_token + tokenizer.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    # as the target is english, the first word to the transformer should be the\n",
    "    # english start token.\n",
    "    decoder_input = [tokenizer.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == tokenizer.vocab_size+1:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    sentence = tokenizer.encode(sentence)\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer.decode([i]) for i in result \n",
    "                            if i < tokenizer.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_verse(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer.decode([i for i in result \n",
    "                                            if i < tokenizer.vocab_size])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted next verse: {}'.format(predicted_sentence))\n",
    "\n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poeme(src = \"\", n_verses = 2):\n",
    "    if src == \"\":\n",
    "        src = input_sequences[np.random.randint(n_seq/2)]\n",
    "    for i in range(n_verses):\n",
    "        result, attention_weights = evaluate(src)\n",
    "\n",
    "        predicted_sentence = tokenizer.decode([i for i in result \n",
    "                                            if i < tokenizer.vocab_size])  \n",
    "        src = predicted_sentence\n",
    "        print(predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.1221 Accuracy 0.0602\n",
      "Epoch 1 Batch 500 Loss 0.9987 Accuracy 0.0623\n",
      "Epoch 1 Batch 1000 Loss 1.2035 Accuracy 0.0695\n",
      "Epoch 1 Batch 1500 Loss 1.5158 Accuracy 0.0817\n",
      "Epoch 1 Batch 2000 Loss 1.7244 Accuracy 0.0945\n",
      "Epoch 1 Batch 2500 Loss 1.8633 Accuracy 0.1038\n",
      "Epoch 1 Batch 3000 Loss 1.9739 Accuracy 0.1109\n",
      "Epoch 1 Loss 1.9883 Accuracy 0.1120\n",
      "Time taken for 1 epoch: 487.6204001903534 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.1880 Accuracy 0.0473\n",
      "Epoch 2 Batch 500 Loss 1.0244 Accuracy 0.0618\n",
      "Epoch 2 Batch 1000 Loss 1.2365 Accuracy 0.0703\n",
      "Epoch 2 Batch 1500 Loss 1.5425 Accuracy 0.0832\n",
      "Epoch 2 Batch 2000 Loss 1.7376 Accuracy 0.0963\n",
      "Epoch 2 Batch 2500 Loss 1.8695 Accuracy 0.1058\n",
      "Epoch 2 Batch 3000 Loss 1.9745 Accuracy 0.1132\n",
      "Epoch 2 Loss 1.9906 Accuracy 0.1143\n",
      "Time taken for 1 epoch: 478.9510681629181 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.0949 Accuracy 0.0407\n",
      "Epoch 3 Batch 500 Loss 1.0025 Accuracy 0.0621\n",
      "Epoch 3 Batch 1000 Loss 1.2059 Accuracy 0.0706\n",
      "Epoch 3 Batch 1500 Loss 1.4969 Accuracy 0.0833\n",
      "Epoch 3 Batch 2000 Loss 1.7001 Accuracy 0.0967\n",
      "Epoch 3 Batch 2500 Loss 1.8372 Accuracy 0.1062\n",
      "Epoch 3 Batch 3000 Loss 1.9482 Accuracy 0.1138\n",
      "Epoch 3 Loss 1.9630 Accuracy 0.1149\n",
      "Time taken for 1 epoch: 481.1125268936157 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.1341 Accuracy 0.0508\n",
      "Epoch 4 Batch 500 Loss 1.0358 Accuracy 0.0638\n",
      "Epoch 4 Batch 1000 Loss 1.2222 Accuracy 0.0725\n",
      "Epoch 4 Batch 1500 Loss 1.5150 Accuracy 0.0852\n",
      "Epoch 4 Batch 2000 Loss 1.6999 Accuracy 0.0984\n",
      "Epoch 4 Batch 2500 Loss 1.8356 Accuracy 0.1080\n",
      "Epoch 4 Batch 3000 Loss 1.9469 Accuracy 0.1158\n",
      "Epoch 4 Loss 1.9591 Accuracy 0.1168\n",
      "Time taken for 1 epoch: 480.0578987598419 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.3193 Accuracy 0.0571\n",
      "Epoch 5 Batch 500 Loss 1.0147 Accuracy 0.0649\n",
      "Epoch 5 Batch 1000 Loss 1.2305 Accuracy 0.0735\n",
      "Epoch 5 Batch 1500 Loss 1.5180 Accuracy 0.0866\n",
      "Epoch 5 Batch 2000 Loss 1.7052 Accuracy 0.1000\n",
      "Epoch 5 Batch 2500 Loss 1.8380 Accuracy 0.1097\n",
      "Epoch 5 Batch 3000 Loss 1.9451 Accuracy 0.1173\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-1\n",
      "Sample of generation\n",
      "je ne sais si je suis, et je ne puis rien dire  \n",
      "que je ne puis souffrir que de me voir coupable.  \n",
      "Epoch 5 Loss 1.9593 Accuracy 0.1184\n",
      "Time taken for 1 epoch: 482.6202747821808 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 500 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "        print('Sample of generation')\n",
    "        generate_poeme()\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
